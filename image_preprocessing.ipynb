{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/PhilipPfeffer/haptic_vest/blob/main/image_preprocessing.ipynb",
      "authorship_tag": "ABX9TyPC69sk9x3Cm3HmWPGYN+HH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhilipPfeffer/haptic_vest/blob/main/image_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvCpSyWlPi0E"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from pycocotools.coco import COCO     # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jieh6dZMb7oq",
        "outputId": "9e85e1e4-c955-453c-ac86-2447eb42e7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# BORROWED FROM DATA_PIPELINE\n",
        "# TODO: CALL FROM DATA_PIPELINE\n",
        "def create_coco(path_to_instances_file, datasetName='val2017'):\n",
        "  annotations=f'{path_to_instances_file}instances_{datasetName}.json'\n",
        "  print(annotations)\n",
        "  \n",
        "  # This line loads annotations from an instances_{datasetName}.json file into a COCO object so we can use the pycoco API\n",
        "  coco = COCO(annotations)\n",
        "  return coco\n",
        "\n",
        "#USAGE\n",
        "dataset_name='train2017'\n",
        "path_to_instances_file ='/content/drive/My Drive/Haptic Vest/coco_dataset/annotations/'\n",
        "coco = create_coco(path_to_instances_file, dataset_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Haptic Vest/coco_dataset/annotations/instances_train2017.json\n",
            "loading annotations into memory...\n",
            "Done (t=16.90s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF04OBHmQPXe"
      },
      "source": [
        "Download the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJBy1Yy9b0my"
      },
      "source": [
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiliahEOQMCh"
      },
      "source": [
        "dataset ='/content/drive/My Drive/Haptic Vest/dataset_person_car'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgGsPcANYt8V"
      },
      "source": [
        "train_ids = np.loadtxt(dataset, dtype=(int, int))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsdi_77cZz29",
        "outputId": "653b5ee2-ac67-459a-d8d1-a4143d788ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_ids, y_train_ids = train_ids[:,0], train_ids[:,1]\n",
        "assert(x_train_ids.shape == y_train_ids.shape)\n",
        "x_train_ids[0], y_train_ids[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262145, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBW2YNvWaUi5"
      },
      "source": [
        "# download_imgs_dir = '/content/drive/My Drive/Haptic Vest/person_car_other_imgs'\n",
        "# coco.download(download_imgs_dir, x_train_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjVbt5_MdPOw"
      },
      "source": [
        "# image_count = 0\n",
        "# for entry in os.scandir(download_imgs_dir):\n",
        "#   image_count += 1\n",
        "#   # print(entry.path)\n",
        "# print(f\"{image_count} images downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW75ZRi2d1pI"
      },
      "source": [
        "# # Process from downloads directory\n",
        "\n",
        "# processed_count = 0\n",
        "# for entry in os.scandir(download_imgs_dir):\n",
        "#   processed_count += 1\n",
        "#   img = io.imread(entry.path)\n",
        "#   img_width = img.shape[0]\n",
        "#   img_height = img.shape[1]\n",
        "#   processed = img\n",
        "  \n",
        "#   # Greyscale\n",
        "#   if len(img.shape) != 2:\n",
        "#     processed = rgb2gray(processed)\n",
        "  \n",
        "#   # Square (centre-crop)\n",
        "#   if img_height != img_width:\n",
        "#     if img_width < img_height:\n",
        "#       height_start = int((img_height - img_width) / 2)\n",
        "#       processed = img[:, height_start:height_start+img_width]\n",
        "#     else:\n",
        "#       width_start = int((img_width - img_height) / 2)\n",
        "#       processed = img[width_start:width_start+img_height,:]\n",
        "  \n",
        "#   # Resize (96x96)\n",
        "#   if img_height != 96:\n",
        "#     processed = resize(processed, (96,96))\n",
        "\n",
        "#   # io.imshow(processed)\n",
        "#   io.imsave(entry.path, processed)\n",
        "\n",
        "# assert(processed_count == image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RFRFZHMfPmq"
      },
      "source": [
        "# # Example image\n",
        "# for i, entry in enumerate(os.scandir(download_imgs_dir)):\n",
        "#   if i == 400:\n",
        "#     img = io.imread(entry.path)\n",
        "#     io.imshow(entry.path)\n",
        "#     print(img.shape)\n",
        "#     print(entry.path)\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qugQpX6ZuAP6"
      },
      "source": [
        "#Process from URL\n",
        "Better than from downloaded images because the original RGB images take up a lot of space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqVXLpXlmRF"
      },
      "source": [
        "download_imgs_dir = '/content/drive/My Drive/Haptic Vest/person_car_other_imgs_processed'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI2ZAw4r7TRj",
        "outputId": "9aa94830-72ef-4ed9-d1c9-44f956193ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_processed_images(download_imgs_dir, total=0):\n",
        "  image_count = 0\n",
        "  for entry in os.scandir(download_imgs_dir):\n",
        "    image_count += 1\n",
        "    # print(entry.path)\n",
        "  print(f\"{image_count}/{total} images downloaded\")\n",
        "\n",
        "count_processed_images(download_imgs_dir, x_train_ids.shape[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77033/77650 images downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiP_3eOV8GJw"
      },
      "source": [
        "already_processed_filenames = [os.path.basename(entry) for entry in os.scandir(download_imgs_dir)]\n",
        "processed_ids = [int(name[:-4]) for name in already_processed_filenames]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt1ymXCN-uvU",
        "outputId": "6550bf15-a7e0-4e86-9bf0-70f3f54e1a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set_difference = set(x_train_ids) - set(processed_ids)\n",
        "remaining_ids = list(set_difference)\n",
        "print(len(remaining_ids))\n",
        "print(remaining_ids[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNjjNaJQuGPC",
        "outputId": "2fef5644-19d1-481c-d38e-3daae7c9f467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Process from URLs\n",
        "\n",
        "processed_count_URL = 0\n",
        "imgs = coco.loadImgs(remaining_ids)\n",
        "checked_already_processed = 0\n",
        "for img_info in imgs:\n",
        "  processed_count_URL += 1\n",
        "\n",
        "  img = io.imread(img_info['coco_url'])\n",
        "  img_filename = img_info['file_name']\n",
        "  img_width = img_info['width']\n",
        "  img_height = img_info['height']\n",
        "  processed = img\n",
        "  \n",
        "  # if img_filename in already_processed_filenames:\n",
        "  #   checked_already_processed += 1\n",
        "  #   if checked_already_processed % 1000:\n",
        "  #     print(f\"{checked_already_processed} of the images checked have already been processed.\")\n",
        "  #   continue\n",
        "\n",
        "  # Greyscale\n",
        "  if len(img.shape) != 2:\n",
        "    processed = rgb2gray(processed)\n",
        "  \n",
        "  # Square (centre-crop)\n",
        "  if img_height != img_width:\n",
        "    if img_width < img_height:\n",
        "      height_start = int((img_height - img_width) / 2)\n",
        "      processed = processed[height_start:height_start+img_width,:]\n",
        "    else:\n",
        "      width_start = int((img_width - img_height) / 2)\n",
        "      processed = processed[:,width_start:width_start+img_height]\n",
        "  \n",
        "  # Resize (96x96)\n",
        "  if img_height != 96:\n",
        "    processed = resize(processed, (96,96))\n",
        "\n",
        "  io.imsave(download_imgs_dir+'/' + img_filename, processed);\n",
        "  \n",
        "  if processed_count_URL % 1000 == 0:\n",
        "    print(f\"\\n{processed_count_URL} images processed\")\n",
        "\n",
        "print(f\"\\nDone!\\n{processed_count_URL} images processed\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n",
            "0 images processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-XWoMQl_dR"
      },
      "source": [
        "dataset ='/content/drive/My Drive/Haptic Vest/dataset_person_car'\n",
        "classes = ['neither', 'person', None , 'car']\n",
        "download_imgs_dir = '/content/drive/My Drive/Haptic Vest/person_car_other_imgs_processed'\n",
        "subset = '/content/drive/My Drive/Haptic Vest/processed_subset1000'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anTR5y0RoDg-"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3HdxnT_Okf",
        "outputId": "c6437de6-7e1c-44ea-8909-10d7cf94cd60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Put 1000 images of each category in new folder\n",
        "person_counter = 0\n",
        "car_counter = 0\n",
        "neither_counter = 0\n",
        "max_imgs = 1000\n",
        "added = 0\n",
        "\n",
        "for img_id, label_idx in zip(x_train_ids, y_train_ids):\n",
        "  label_name = classes[label_idx]\n",
        "  num_zeros = len('000000000036') - len(str(img_id))\n",
        "  file_name = download_imgs_dir + '/' + '0'*num_zeros + str(img_id) + '.jpg'\n",
        "  dest_img = subset + '/' + '0'*num_zeros + str(img_id) + '.jpg'\n",
        "\n",
        "  if label_idx == 0:\n",
        "    if neither_counter == max_imgs:\n",
        "      continue\n",
        "    shutil.copyfile(file_name, dest_img)\n",
        "    neither_counter +=1\n",
        "    added += 1\n",
        "    if added % 20 == 0:\n",
        "      print(added)\n",
        "\n",
        "  if label_idx == 1:\n",
        "    if person_counter == max_imgs:\n",
        "      continue\n",
        "    shutil.copyfile(file_name, dest_img)\n",
        "    person_counter += 1\n",
        "    added += 1\n",
        "    if added % 20 == 0:\n",
        "      print(added)\n",
        "\n",
        "  if label_idx == 3:\n",
        "    if car_counter == max_imgs:\n",
        "      continue\n",
        "    shutil.copyfile(file_name, dest_img)\n",
        "    car_counter += 1\n",
        "    added += 1\n",
        "    if added % 20 == 0:\n",
        "      print(added)\n",
        "\n",
        "  # break"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "400\n",
            "420\n",
            "440\n",
            "460\n",
            "480\n",
            "500\n",
            "520\n",
            "540\n",
            "560\n",
            "580\n",
            "600\n",
            "620\n",
            "640\n",
            "660\n",
            "680\n",
            "700\n",
            "720\n",
            "740\n",
            "760\n",
            "780\n",
            "800\n",
            "820\n",
            "840\n",
            "860\n",
            "880\n",
            "900\n",
            "920\n",
            "940\n",
            "960\n",
            "980\n",
            "1000\n",
            "1020\n",
            "1040\n",
            "1060\n",
            "1080\n",
            "1100\n",
            "1120\n",
            "1140\n",
            "1160\n",
            "1180\n",
            "1200\n",
            "1220\n",
            "1240\n",
            "1260\n",
            "1280\n",
            "1300\n",
            "1320\n",
            "1340\n",
            "1360\n",
            "1380\n",
            "1400\n",
            "1420\n",
            "1440\n",
            "1460\n",
            "1480\n",
            "1500\n",
            "1520\n",
            "1540\n",
            "1560\n",
            "1580\n",
            "1600\n",
            "1620\n",
            "1640\n",
            "1660\n",
            "1680\n",
            "1700\n",
            "1720\n",
            "1740\n",
            "1760\n",
            "1780\n",
            "1800\n",
            "1820\n",
            "1840\n",
            "1860\n",
            "1880\n",
            "1900\n",
            "1920\n",
            "1940\n",
            "1960\n",
            "1980\n",
            "2000\n",
            "2020\n",
            "2040\n",
            "2060\n",
            "2080\n",
            "2100\n",
            "2120\n",
            "2140\n",
            "2160\n",
            "2180\n",
            "2200\n",
            "2220\n",
            "2240\n",
            "2260\n",
            "2280\n",
            "2300\n",
            "2320\n",
            "2340\n",
            "2360\n",
            "2380\n",
            "2400\n",
            "2420\n",
            "2440\n",
            "2460\n",
            "2480\n",
            "2500\n",
            "2520\n",
            "2540\n",
            "2560\n",
            "2580\n",
            "2600\n",
            "2620\n",
            "2640\n",
            "2660\n",
            "2680\n",
            "2700\n",
            "2720\n",
            "2740\n",
            "2760\n",
            "2780\n",
            "2800\n",
            "2820\n",
            "2840\n",
            "2860\n",
            "2880\n",
            "2900\n",
            "2920\n",
            "2940\n",
            "2960\n",
            "2980\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck7xM5o8pjhA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}