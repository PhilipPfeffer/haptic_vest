{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Sg6B0Q5wZ81jT9m5sZSzWLvaA6h10jBf",
      "authorship_tag": "ABX9TyOfQk10LzraH6KTUcw+JVTl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhilipPfeffer/haptic_vest/blob/main/image_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvCpSyWlPi0E"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from pycocotools.coco import COCO     # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jieh6dZMb7oq",
        "outputId": "b808b84e-bde2-4f9a-c386-76b4d7aae346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# BORROWED FROM DATA_PIPELINE\n",
        "# TODO: CALL FROM DATA_PIPELINE\n",
        "def create_coco(path_to_instances_file, datasetName='val2017'):\n",
        "  annotations=f'{path_to_instances_file}instances_{datasetName}.json'\n",
        "  print(annotations)\n",
        "  \n",
        "  # This line loads annotations from an instances_{datasetName}.json file into a COCO object so we can use the pycoco API\n",
        "  coco = COCO(annotations)\n",
        "  return coco\n",
        "\n",
        "#USAGE\n",
        "dataset_name='train2017'\n",
        "path_to_instances_file ='/content/drive/My Drive/Haptic Vest/coco_dataset/annotations/'\n",
        "coco = create_coco(path_to_instances_file, dataset_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Haptic Vest/coco_dataset/annotations/instances_train2017.json\n",
            "loading annotations into memory...\n",
            "Done (t=17.42s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF04OBHmQPXe"
      },
      "source": [
        "Download the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJBy1Yy9b0my"
      },
      "source": [
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiliahEOQMCh"
      },
      "source": [
        "dataset ='/content/drive/My Drive/Haptic Vest/dataset_person_car'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgGsPcANYt8V"
      },
      "source": [
        "train_ids = np.loadtxt(dataset, dtype=(int, int))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsdi_77cZz29",
        "outputId": "10a9090c-f29b-4c42-f45a-a67ebef01ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_ids, y_train_ids = train_ids[:,0], train_ids[:,1]\n",
        "assert(x_train_ids.shape == y_train_ids.shape)\n",
        "x_train_ids[0], y_train_ids[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262145, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBW2YNvWaUi5"
      },
      "source": [
        "# download_imgs_dir = '/content/drive/My Drive/Haptic Vest/person_car_other_imgs'\n",
        "# coco.download(download_imgs_dir, x_train_ids)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjVbt5_MdPOw"
      },
      "source": [
        "# image_count = 0\n",
        "# for entry in os.scandir(download_imgs_dir):\n",
        "#   image_count += 1\n",
        "#   # print(entry.path)\n",
        "# print(f\"{image_count} images downloaded\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW75ZRi2d1pI"
      },
      "source": [
        "# # Process from downloads directory\n",
        "\n",
        "# processed_count = 0\n",
        "# for entry in os.scandir(download_imgs_dir):\n",
        "#   processed_count += 1\n",
        "#   img = io.imread(entry.path)\n",
        "#   img_width = img.shape[0]\n",
        "#   img_height = img.shape[1]\n",
        "#   processed = img\n",
        "  \n",
        "#   # Greyscale\n",
        "#   if len(img.shape) != 2:\n",
        "#     processed = rgb2gray(processed)\n",
        "  \n",
        "#   # Square (centre-crop)\n",
        "#   if img_height != img_width:\n",
        "#     if img_width < img_height:\n",
        "#       height_start = int((img_height - img_width) / 2)\n",
        "#       processed = img[:, height_start:height_start+img_width]\n",
        "#     else:\n",
        "#       width_start = int((img_width - img_height) / 2)\n",
        "#       processed = img[width_start:width_start+img_height,:]\n",
        "  \n",
        "#   # Resize (96x96)\n",
        "#   if img_height != 96:\n",
        "#     processed = resize(processed, (96,96))\n",
        "\n",
        "#   # io.imshow(processed)\n",
        "#   io.imsave(entry.path, processed)\n",
        "\n",
        "# assert(processed_count == image_count)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RFRFZHMfPmq"
      },
      "source": [
        "# # Example image\n",
        "# for i, entry in enumerate(os.scandir(download_imgs_dir)):\n",
        "#   if i == 400:\n",
        "#     img = io.imread(entry.path)\n",
        "#     io.imshow(entry.path)\n",
        "#     print(img.shape)\n",
        "#     print(entry.path)\n",
        "#     break"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qugQpX6ZuAP6"
      },
      "source": [
        "#Process from URL\n",
        "Better than from downloaded images because the original RGB images take up a lot of space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqVXLpXlmRF"
      },
      "source": [
        "download_imgs_dir = '/content/drive/My Drive/Haptic Vest/person_car_other_imgs_processed'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI2ZAw4r7TRj",
        "outputId": "18e8de1e-d4fb-44cb-d249-c1a1d1ef9ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_processed_images(download_imgs_dir, total=0):\n",
        "  image_count = 0\n",
        "  for entry in os.scandir(download_imgs_dir):\n",
        "    image_count += 1\n",
        "    # print(entry.path)\n",
        "  print(f\"{image_count}/{total} images downloaded\")\n",
        "\n",
        "count_processed_images(download_imgs_dir, x_train_ids.shape[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77033/77650 images downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiP_3eOV8GJw"
      },
      "source": [
        "already_processed_filenames = [os.path.basename(entry) for entry in os.scandir(download_imgs_dir)]\n",
        "processed_ids = [int(name[:-4]) for name in already_processed_filenames]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt1ymXCN-uvU",
        "outputId": "3b42417a-4acf-43de-deb0-fb4584d076e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "set_difference = set(x_train_ids) - set(processed_ids)\n",
        "remaining_ids = list(set_difference)\n",
        "print(len(remaining_ids))\n",
        "print(remaining_ids[:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNjjNaJQuGPC",
        "outputId": "6418f31b-e93a-45ce-dd99-f5570b5ab03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Process from URLs\n",
        "\n",
        "processed_count_URL = 0\n",
        "imgs = coco.loadImgs(remaining_ids)\n",
        "checked_already_processed = 0\n",
        "for img_info in imgs:\n",
        "  processed_count_URL += 1\n",
        "\n",
        "  img = io.imread(img_info['coco_url'])\n",
        "  img_filename = img_info['file_name']\n",
        "  img_width = img_info['width']\n",
        "  img_height = img_info['height']\n",
        "  processed = img\n",
        "  \n",
        "  # if img_filename in already_processed_filenames:\n",
        "  #   checked_already_processed += 1\n",
        "  #   if checked_already_processed % 1000:\n",
        "  #     print(f\"{checked_already_processed} of the images checked have already been processed.\")\n",
        "  #   continue\n",
        "\n",
        "  # Greyscale\n",
        "  if len(img.shape) != 2:\n",
        "    processed = rgb2gray(processed)\n",
        "  \n",
        "  # Square (centre-crop)\n",
        "  if img_height != img_width:\n",
        "    if img_width < img_height:\n",
        "      height_start = int((img_height - img_width) / 2)\n",
        "      processed = processed[height_start:height_start+img_width,:]\n",
        "    else:\n",
        "      width_start = int((img_width - img_height) / 2)\n",
        "      processed = processed[:,width_start:width_start+img_height]\n",
        "  \n",
        "  # Resize (96x96)\n",
        "  if img_height != 96:\n",
        "    processed = resize(processed, (96,96))\n",
        "\n",
        "  io.imsave(download_imgs_dir+'/' + img_filename, processed);\n",
        "  \n",
        "  if processed_count_URL % 1000 == 0:\n",
        "    print(f\"\\n{processed_count_URL} images processed\")\n",
        "\n",
        "print(f\"\\nDone!\\n{processed_count_URL} images processed\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n",
            "0 images processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3HdxnT_Okf"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcwLA0YR_152"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}